{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/lightfm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/lightfm/lib/python3.10/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import spacy\n",
    "from keybert import KeyBERT\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from rake_nltk import Rake\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm.evaluation import auc_score, precision_at_k, recall_at_k, reciprocal_rank\n",
    "from lightfm.cross_validation import random_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyWordExtractor(ABC):\n",
    "    @abstractmethod\n",
    "    def extract(self, text) -> list[str]:\n",
    "        pass\n",
    "\n",
    "class SpacyExtractor(KeyWordExtractor):\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    def extract(self, text):\n",
    "        doc = self.nlp(text)\n",
    "        return [chunk.text for chunk in doc.noun_chunks]\n",
    "    \n",
    "class KeybertExtractor(KeyWordExtractor):\n",
    "    def __init__(self):\n",
    "        self.model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "\n",
    "    def extract(self, text):\n",
    "        return [kw for (kw, _) in self.model.extract_keywords(text)]\n",
    "    \n",
    "class GensimExtractor(KeyWordExtractor):\n",
    "    def extract(self, text):\n",
    "        texts = [doc.lower().split() for doc in text.strip().split()]\n",
    "        dct = Dictionary(texts)\n",
    "        corpus = [dct.doc2bow(line) for line in texts]\n",
    "        model = TfidfModel(corpus)\n",
    "        kw = []\n",
    "        for doc in corpus:\n",
    "            for (id, score) in model[doc]:\n",
    "                kw.append(dct[id])\n",
    "        return kw\n",
    "    \n",
    "class RakeExtractor(KeyWordExtractor):\n",
    "    def __init__(self):\n",
    "        self.rake = Rake()\n",
    "\n",
    "    def extract(self, text):\n",
    "        self.rake.extract_keywords_from_text(text)\n",
    "        return self.rake.get_ranked_phrases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings columns:  Index(['userId', 'itemId', 'timestamp', 'rating'], dtype='object')\n",
      "Ratings size:  659720\n",
      "Content columns:  Index(['itemId', 'title', 'year', 'rated', 'released', 'runtime', 'genre',\n",
      "       'director', 'writer', 'actors', 'plot', 'language', 'country', 'awards',\n",
      "       'poster', 'ratings', 'metascore', 'imdbRating', 'imdbVotes', 'type',\n",
      "       'dVD', 'boxOffice', 'production', 'website', 'response', 'totalSeasons',\n",
      "       'season', 'episode', 'seriesID'],\n",
      "      dtype='object')\n",
      "Content size:  38012\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_json('ratings.jsonl', lines=True)\n",
    "ratings.rename(columns={col: col[0].lower() + col[1:] for col in ratings.columns}, inplace=True)\n",
    "content = pd.read_json('content.jsonl', lines=True)\n",
    "content.rename(columns={col: col[0].lower() + col[1:] for col in content.columns}, inplace=True)\n",
    "\n",
    "print(\"Ratings columns: \", ratings.columns)\n",
    "print(\"Ratings size: \", len(ratings))\n",
    "print(\"Content columns: \", content.columns)\n",
    "print(\"Content size: \", len(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users:  51671\n",
      "Unique users:  ['c4ca4238a0', 'c81e728d9d', 'a87ff679a2', 'e4da3b7fbb', '1679091c5a']\n",
      "Number of unique items:  38012\n",
      "Unique items:  ['c9f0f895fb', 'd3d9446802', 'c20ad4d76f', '8e296a067a', '54229abfcf']\n",
      "Sparsity:  0.00033588612422162087\n"
     ]
    }
   ],
   "source": [
    "unique_users = ratings['userId'].unique().tolist()\n",
    "unique_items = content['itemId'].unique().tolist()\n",
    "\n",
    "print(\"Number of unique users: \", len(unique_users))\n",
    "print(\"Unique users: \", unique_users[:5])\n",
    "print(\"Number of unique items: \", len(unique_items))\n",
    "print(\"Unique items: \", unique_items[:5])\n",
    "print(\"Sparsity: \", len(ratings) / (len(unique_users) * len(unique_items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users:  51671\n",
      "Number of items:  38012\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset()\n",
    "\n",
    "dataset.fit(\n",
    "    users=unique_users,\n",
    "    items=unique_items,\n",
    ")\n",
    "\n",
    "num_users, num_items = dataset.interactions_shape() \n",
    "print(\"Number of users: \", num_users)\n",
    "print(\"Number of items: \", num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train interactions:  <51671x38012 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 527776 stored elements in COOrdinate format>\n",
      "Test interactions:  <51671x38012 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 131944 stored elements in COOrdinate format>\n"
     ]
    }
   ],
   "source": [
    "(interactions, weights) = dataset.build_interactions(\n",
    "    (row['userId'], row['itemId'], row['rating']) for _, row in ratings.iterrows()\n",
    ")\n",
    "\n",
    "train, test = random_train_test_split(interactions, test_percentage=0.2, random_state=42)\n",
    "\n",
    "print(\"Train interactions: \", repr(train))\n",
    "print(\"Test interactions: \", repr(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 30/30 [00:07<00:00,  3.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x30df74580>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(loss='warp')\n",
    "model.fit(\n",
    "    interactions=train,\n",
    "    epochs=30,\n",
    "    num_threads=2,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC train: 0.9894445538520813\n",
      "AUC test: 0.9538678526878357\n",
      "Precision at 10 train: 0.07502986490726471\n",
      "Precision at 10 test: 0.04026177152991295\n",
      "Recall at 10 train: 0.15744960779187292\n",
      "Recall at 10 test: 0.0947027604226028\n",
      "Reciprocal rank train: 0.197854682803154\n",
      "Reciprocal rank test: 0.1224101185798645\n"
     ]
    }
   ],
   "source": [
    "auc_train = auc_score(model, train).mean()\n",
    "auc_test = auc_score(model, test, train_interactions=train).mean()\n",
    "print(f'AUC train: {auc_train}')\n",
    "print(f'AUC test: {auc_test}')\n",
    "\n",
    "precision_at_10_train = precision_at_k(model, train, k=10).mean()\n",
    "precision_at_10_test = precision_at_k(model, test, train_interactions=train, k=10).mean()\n",
    "print(f'Precision at 10 train: {precision_at_10_train}')\n",
    "print(f'Precision at 10 test: {precision_at_10_test}')\n",
    "\n",
    "recall_at_10_train = recall_at_k(model, train, k=10).mean()\n",
    "recall_at_10_test = recall_at_k(model, test, train_interactions=train, k=10).mean()\n",
    "print(f'Recall at 10 train: {recall_at_10_train}')\n",
    "print(f'Recall at 10 test: {recall_at_10_test}')\n",
    "\n",
    "reciprocal_rank_train = reciprocal_rank(model, train).mean()\n",
    "reciprocal_rank_test = reciprocal_rank(model, test, train_interactions=train).mean()\n",
    "print(f'Reciprocal rank train: {reciprocal_rank_train}')\n",
    "print(f'Reciprocal rank test: {reciprocal_rank_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0006246bee</td>\n",
       "      <td>80d1dae630</td>\n",
       "      <td>2.960773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0006246bee</td>\n",
       "      <td>ade4907055</td>\n",
       "      <td>0.064699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0006246bee</td>\n",
       "      <td>aad36aac60</td>\n",
       "      <td>-0.253012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0006246bee</td>\n",
       "      <td>899610035b</td>\n",
       "      <td>-0.531327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0006246bee</td>\n",
       "      <td>c1ee6829f5</td>\n",
       "      <td>-0.566963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616146</th>\n",
       "      <td>fffffe98d0</td>\n",
       "      <td>6b2efec875</td>\n",
       "      <td>-6.812146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616126</th>\n",
       "      <td>fffffe98d0</td>\n",
       "      <td>36122c9ac8</td>\n",
       "      <td>-6.816423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616166</th>\n",
       "      <td>fffffe98d0</td>\n",
       "      <td>9cefd28595</td>\n",
       "      <td>-6.934533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616137</th>\n",
       "      <td>fffffe98d0</td>\n",
       "      <td>51d77b425e</td>\n",
       "      <td>-7.037381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616132</th>\n",
       "      <td>fffffe98d0</td>\n",
       "      <td>46e876dfe5</td>\n",
       "      <td>-7.102859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>616200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            UserId      ItemId     Score\n",
       "44      0006246bee  80d1dae630  2.960773\n",
       "60      0006246bee  ade4907055  0.064699\n",
       "59      0006246bee  aad36aac60 -0.253012\n",
       "50      0006246bee  899610035b -0.531327\n",
       "69      0006246bee  c1ee6829f5 -0.566963\n",
       "...            ...         ...       ...\n",
       "616146  fffffe98d0  6b2efec875 -6.812146\n",
       "616126  fffffe98d0  36122c9ac8 -6.816423\n",
       "616166  fffffe98d0  9cefd28595 -6.934533\n",
       "616137  fffffe98d0  51d77b425e -7.037381\n",
       "616132  fffffe98d0  46e876dfe5 -7.102859\n",
       "\n",
       "[616200 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = pd.read_csv('targets.csv')\n",
    "target_userIds = targets['UserId'].map(dataset.mapping()[0]).to_numpy()\n",
    "target_itemIds = targets['ItemId'].map(dataset.mapping()[2]).to_numpy()\n",
    "targets['Score'] = model.predict(target_userIds, target_itemIds)\n",
    "targets.sort_values(by=['UserId', 'Score'], ascending=[True, False], inplace=True)\n",
    "targets[[\"UserId\", \"ItemId\"]].to_csv(f'./submissions/lightfm2-submission_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv', index=False)\n",
    "targets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
