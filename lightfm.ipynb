{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/recsys/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/recsys/lib/python3.10/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from lightfm import LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings columns:  Index(['userId', 'itemId', 'rating'], dtype='object')\n",
      "Ratings size:  659720\n",
      "Content columns:  Index(['itemId', 'title', 'year', 'rated', 'released', 'runtime', 'genre',\n",
      "       'director', 'writer', 'actors', 'plot', 'language', 'country', 'awards',\n",
      "       'poster', 'ratings', 'metascore', 'imdbRating', 'imdbVotes', 'type',\n",
      "       'dVD', 'boxOffice', 'production', 'website', 'response', 'totalSeasons',\n",
      "       'season', 'episode', 'seriesID'],\n",
      "      dtype='object')\n",
      "Content size:  38012\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_json('ratings.jsonl', lines=True).drop(columns=['Timestamp'])\n",
    "ratings.rename(columns={col: col[0].lower() + col[1:] for col in ratings.columns}, inplace=True)\n",
    "content = pd.read_json('content.jsonl', lines=True)\n",
    "content.rename(columns={col: col[0].lower() + col[1:] for col in content.columns}, inplace=True)\n",
    "targets = pd.read_csv('targets.csv')\n",
    "targets.rename(columns={col: col[0].lower() + col[1:] for col in targets.columns}, inplace=True)\n",
    "\n",
    "print(\"Ratings columns: \", ratings.columns)\n",
    "print(\"Ratings size: \", len(ratings))\n",
    "print(\"Content columns: \", content.columns)\n",
    "print(\"Content size: \", len(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = ratings['userId'].unique()\n",
    "unique_items = content['itemId'].unique()\n",
    "\n",
    "n_usr = len(unique_users)\n",
    "n_itm = len(unique_items)\n",
    "\n",
    "user_indexes = {user: i for i, user in enumerate(unique_users)}\n",
    "item_indexes = {item: i for i, item in enumerate(unique_items)}\n",
    "\n",
    "user_reverse_indexes = {idx: user for user, idx in user_indexes.items()} \n",
    "item_reverse_indexes = {idx: item for item, idx in item_indexes.items()}\n",
    "\n",
    "ratings['userId'] = ratings['userId'].apply(lambda x: user_indexes[x])\n",
    "ratings['itemId'] = ratings['itemId'].apply(lambda x: item_indexes[x])\n",
    "content['itemId'] = content['itemId'].apply(lambda x: item_indexes[x])\n",
    "targets['userId'] = targets['userId'].apply(lambda x: user_indexes[x])\n",
    "targets['itemId'] = targets['itemId'].apply(lambda x: item_indexes[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_matrix = coo_matrix(\n",
    "    (ratings['rating'], (ratings['userId'], ratings['itemId']))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "content['title'] = content['title'].replace('N/A', None)\n",
    "content['genre'] = content['genre'].replace('N/A', None)\n",
    "content['director'] = content['director'].replace('N/A', None)\n",
    "content['writer'] = content['writer'].replace('N/A', None)\n",
    "content['actors'] = content['actors'].replace('N/A', None)\n",
    "content['plot'] = content['plot'].replace('N/A', None)\n",
    "content['awards'] = content['awards'].replace('N/A', None)\n",
    "\n",
    "def combination(row):\n",
    "    template = \"\"\n",
    "\n",
    "    if pd.notna(row['title']):\n",
    "        template += f'{row[\"title\"]} '\n",
    "    if pd.notna(row['genre']):\n",
    "        template += f'{row[\"genre\"]} '\n",
    "    if pd.notna(row['director']):\n",
    "        template += f'{row[\"director\"]} '\n",
    "    if pd.notna(row['writer']):\n",
    "        template += f'{row[\"writer\"]} '\n",
    "    if pd.notna(row['actors']):\n",
    "        template += f'{row[\"actors\"]} '\n",
    "    if pd.notna(row['plot']):\n",
    "        template += f'{row[\"plot\"]} '\n",
    "    if pd.notna(row['awards']):\n",
    "        template += f'{row[\"awards\"]} '\n",
    "    \n",
    "    return template\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "text_features = vectorizer.fit_transform(content.apply(combination, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "content['imdbRating'] = pd.to_numeric(content['imdbRating'], errors='coerce')\n",
    "content['imdbRating'] = content['imdbRating'].fillna(content['imdbRating'].median())\n",
    "content['imdbVotes'] = pd.to_numeric(content['imdbVotes'], errors='coerce')\n",
    "content['imdbVotes'] = content['imdbVotes'].fillna(0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "content[['imdbRating', 'imdbVotes']] = scaler.fit_transform(content[['imdbRating', 'imdbVotes']])\n",
    "num_features = coo_matrix(content[['imdbRating', 'imdbVotes']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = hstack([text_features, num_features])\n",
    "item_features_matrix = coo_matrix(combined_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x3335b6ef0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(loss='warp', no_components=50)\n",
    "\n",
    "model.fit(\n",
    "    interaction_matrix,\n",
    "    item_features=item_features_matrix,\n",
    "    epochs=30,\n",
    "    num_threads=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets['Score'] = model.predict(targets['userId'].to_numpy(), targets['itemId'].to_numpy(), item_features=item_features_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets['UserId'] = targets['userId'].apply(lambda x: user_reverse_indexes[x])\n",
    "targets['ItemId'] = targets['itemId'].apply(lambda x: item_reverse_indexes[x])\n",
    "targets.sort_values(by=['UserId', 'Score'], ascending=[True, False], inplace=True)\n",
    "targets.to_csv(f'./submissions/lightfm-cb-submission_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv', index=False, columns=['UserId', 'ItemId'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
